**Описание Работы Скрипта Предобработки**

Исходя из структуры проекта и плана реализации (`implementation_plan.md`), скрипт предобработки (предположительно `scripts/preprocess.js` или аналогичный файл внутри `scripts/`) должен работать следующим образом:

1.  **Запуск:** Скрипт запускается командой вида `npm run preprocess -- --module=<id>`, где `<id>` - это идентификатор модуля, который нужно обработать.
2.  **Получение Исходных Файлов:**
    *   Сначала скрипт обращается к `src/utils/git_fetcher.js`, чтобы убедиться, что локальная копия репозитория с исходными `.md` и `.docx` файлами (находящаяся в папке `source_md/`) актуальна. Он либо клонирует репозиторий (если папки `source_md/` нет), либо обновляет его (`git pull`). Путь к репозиторию и данные для аутентификации берутся из файла `.env`.
    *   Далее скрипт ищет директорию, соответствующую указанному `module_id` внутри `source_md/`.
3.  **Поиск и Конвертация DOCX:**
    *   Внутри директории модуля скрипт находит все файлы с расширением `.docx`.
    *   Для каждого найденного `.docx` файла он вызывает утилиту `pandoc` (установленную в системе или Docker-контейнере) для конвертации его в формат Markdown (`.md`). Медиа-файлы (изображения) из `.docx` извлекаются в подпапку `media`.
4.  **Обработка Markdown Файлов:**
    *   Скрипт находит все `.md` файлы в директории модуля (включая только что сконвертированные).
    *   Для каждого `.md` файла выполняются следующие шаги:
        *   **Замена Изображений на Mermaid:** Файл парсится для поиска тегов изображений (`![]()` или `<img>`). Для каждого изображения делается запрос к API OpenRouter (используя ключ из `.env`) с промптом для генерации Mermaid-диаграммы, описывающей это изображение. Найденный тег изображения заменяется на блок кода Mermaid ```mermaid ... ```.
        *   **Разделение на Чанки:** Обработанный Markdown-контент разделяется на части (чанки).
            *   **Первичное разделение:** Происходит по заголовкам определенного уровня (например, `##`, уровень задается в `.env`).
            *   **Вторичное разделение (при необходимости):** Если чанк, полученный после разделения по заголовку, слишком длинный (превышает лимит символов, заданный в `.env`), он делится на более мелкие под-чанки по границам предложений или абзацев.
        *   **Сбор Метаданных:** Для каждого итогового чанка (или под-чанка) сохраняется его текст и метаданные: имя исходного файла, `module_id`, иерархия заголовков, порядковый номер чанка и, возможно, под-чанка.
5.  **Сохранение Результатов:**
    *   Все полученные чанки для указанного модуля собираются в единый массив.
    *   Этот массив сохраняется в виде JSON-файла в папку `output/`, например, `output/preprocessed_chunks_${moduleId}.json`.
6.  **Логирование:** На всех этапах работы скрипт выводит информационные сообщения и ошибки в консоль или лог-файл.

Таким образом, скрипт автоматизирует весь процесс подготовки текстовых данных из разных форматов к дальнейшей обработке LLM и загрузке в базы данных. 
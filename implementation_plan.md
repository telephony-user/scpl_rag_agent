**Детализированный План Реализации и Передачи Проекта (на основе PRD v1.3)**

### **Фаза 1: Подготовка и Базовая Настройка (Оценка: 3-5 дней)**

**Цель:** Создать основу проекта, настроить окружение и обеспечить базовый доступ к данным.
1. **Создание Репозитория Проекта:**
    - Инициализировать Git-репозиторий для кода Node.js.
    - Настроить базовую структуру папок (src, scripts, config, tests, docs).
    - Создать `.gitignore` (включить `.env`, `node_modules`, `dist`, и т.д.).
2. **Настройка Среды Разработки:**
    - Следовать "Руководству по Настройке Среды Разработки" из `prd_assumptions_setup_guide`.
    - Установить Node.js, npm, Docker, Pandoc.
    - Создать базовый `package.json`.
    - Установить основные зависимости: `dotenv`, фреймворк для логирования (`pino`/`winston`), базовые утилиты, **клиент для PostgreSQL (например, `pg`)**.
	
3. **Настройка Docker (Базовая):**
    - Создать начальный `Dockerfile` для Node.js приложения.
    - (Опционально) Создать `docker-compose.yml` для локального запуска PostgreSQL и Qdrant (для разработки/тестирования).
	
4. **Настройка Доступа к Git (Источник MD):**
    - Реализовать скрипт/модуль на Node.js (используя `simple-git` или `child_process`) для:
        - Клонирования/обновления репозитория с MD-файлами по URL из `.env`.
        - Обработки аутентификации (SSH-ключ/токен из `.env`).
        - Определения `module_id` по структуре папок.
    - Настроить переменные окружения (`GIT_REPO_URL`, `GIT_SSH_KEY_PATH`/`GIT_ACCESS_TOKEN`).
        
5. **Настройка Подключения к Базам Данных:**
    - Установить клиенты: **`pg` (или выбранный ORM)**, `@qdrant/js-client`.
    - Реализовать модули конфигурации для подключения к PostgreSQL и Qdrant, используя данные из `.env`.
    - Написать простые тесты подключения к БД (локально или на Coolify).
    - Настроить переменные окружения (`DATABASE_URL` или `PG_HOST`, `PG_PORT`, `PG_USER`, `PG_PASSWORD`, `PG_DATABASE`, `QDRANT_URL`, `QDRANT_API_KEY` и т.д.).
        
6. **Проверка Предположения 6 (Coolify):**
    
    - Развернуть "hello-world" Node.js, PostgreSQL, Qdrant на Coolify.

    Хорошо, давайте детально разберем, как выполнить пункт 1.6 для проверки развертывания на Coolify, используя созданный `hello-world` пример.

    **Предварительные шаги:**

    1.  **Git Репозиторий:** Убедитесь, что папка `hello-world` со всеми файлами (`index.js`, `package.json`, `Dockerfile`, `docker-compose.yml`) добавлена, закоммичена и отправлена (pushed) в Git-репозиторий (например, на GitHub, GitLab, Bitbucket), к которому у вашего Coolify есть доступ.
    2.  **Доступ Coolify: как настроить подключение к Git-репозиторию?**
        - Войдите в веб‑интерфейс Coolify → раздел «Settings» → «Integrations» → «Git Provider».
        - Для SSH‑доступа:
            1. Сгенерируйте SSH‑ключ: ssh-keygen -t ed25519 -C "coolify".
            2. Добавьте публичный ключ (id_ed25519.pub) в раздел SSH‑keys вашего репозитория на GitHub/GitLab.
            3. В настройках Coolify загрузите приватный ключ (id_ed25519).
        - Для доступа через GitHub App:
            1. Нажмите «Connect with GitHub» и авторизуйте Coolify как GitHub App.
            2. Выберите нужные репозитории и подтвердите доступ.
        - Убедитесь, что статус подключения отображается как «Connected», а ваш репозиторий доступен для деплоя.

    **Шаги в интерфейсе Coolify:**

    1.  **Вход и Создание Проекта:**
        *   Войдите в свой Coolify.
        *   Перейдите в раздел "Projects".
        *   Нажмите "Create New Project".
        *   Дайте проекту имя, например, `SCPL Test Deployment`.

    2.  **Добавление Источника (Source):**
        *   Внутри нового проекта перейдите на вкладку "Sources".
        *   Нажмите "Add Source".
        *   Выберите ваш Git-провайдер (GitHub, GitLab и т.д.).
        *   Выберите репозиторий, содержащий ваш проект (включая папку `hello-world`).

    3.  **Развертывание PostgreSQL:**
        *   Перейдите на вкладку "Resources" вашего проекта.
        *   Нажмите "Add Resource".
        *   Выберите тип ресурса: "PostgreSQL".
        *   Задайте имя сервиса, например, `test-postgres`.
        *   Выберите желаемую версию PostgreSQL (например, 15).
        *   Coolify обычно автоматически генерирует пользователя, пароль и имя базы данных. Вы можете найти их на вкладке "Environment Variables" созданного ресурса PostgreSQL *после* первого деплоя, или задать свои переменные `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB` перед деплоем.
        *   Нажмите "Deploy". Дождитесь статуса `Running`.

    4.  **Развертывание Qdrant:**
        *   Снова нажмите "Add Resource".
        *   Выберите тип ресурса: "Qdrant" (если доступно) или "Docker Image".
            *   **Если выбрали "Qdrant":**
                *   Задайте имя, например, `test-qdrant`.
                *   Убедитесь, что порт `6333` указан.
                *   Если используете API-ключ, добавьте переменную окружения `QDRANT_API_KEY` с вашим ключом.
            *   **Если выбрали "Docker Image":**
                *   Задайте имя, например, `test-qdrant`.
                *   В поле "Image" укажите `qdrant/qdrant:v1.7.4`.
                *   В настройках сети (Networking) укажите порт `6333`.
                *   Если используете API-ключ, добавьте переменную окружения `QDRANT_API_KEY` с вашим ключом.
        *   Нажмите "Deploy". Дождитесь статуса `Running`.

    5.  **Развертывание Node.js Приложения (`hello-world`):**
        *   Снова нажмите "Add Resource".
        *   Выберите тип ресурса: "Application".
        *   **General:**
            *   Задайте имя, например, `test-hello-world-app`.
            *   Выберите Git Source (ваш репозиторий) и нужную ветку.
        *   **Build:**
            *   Выберите "Dockerfile" как Build Pack.
            *   **Dockerfile Location:** `/hello-world/Dockerfile` (Путь от корня репозитория).
            *   **Base Directory:** `/hello-world/` (Указывает, что команды типа `COPY` в Dockerfile должны работать относительно этой папки).
        *   **Network:**
            *   **Ports:** Укажите `3000` (порт, который слушает ваше Node.js приложение). Coolify автоматически назначит внешний порт.
        *   **(Опционально, для демонстрации связей)**: На вкладке "Environment Variables" можно добавить переменные для подключения к другим сервисам, используя внутренние DNS-имена Coolify (они обычно совпадают с именами сервисов):
            *   `POSTGRES_URL=postgresql://<user>:<password>@test-postgres:5432/<database>` (замените `<user>`, `<password>`, `<database>` на значения из шага 3).
            *   `QDRANT_URL=http://test-qdrant:6333`
            *   (Хотя само приложение `hello-world` их не использует, это показывает, как вы будете настраивать основное приложение).
        *   Нажмите "Deploy". Дождитесь статуса `Running`.

    6.  **Проверка и Валидация:**
        *   Убедитесь, что все три ресурса (`test-postgres`, `test-qdrant`, `test-hello-world-app`) имеют статус `Running`.
        *   Проверьте логи каждого ресурса на вкладке "Logs" на наличие ошибок запуска или работы.

    7.  **Тестирование Сетевого Взаимодействия:**
        *   **Node.js App:**
            *   На странице ресурса `test-hello-world-app` сгенерированный FQDN (Public URL) : 
            *   Откройте в браузере или используйте `curl`: `curl http://<ваш-fqdn>/health`. Вы должны увидеть ответ `OK`.
        *   **PostgreSQL:**
            *   На странице ресурса `test-postgres` найдите данные для подключения (хост, порт, пользователь, пароль, база данных). Они могут быть доступны как переменные окружения или на отдельной вкладке.
            *   Используйте любой SQL-клиент (psql, DBeaver, pgAdmin) для подключения к базе данных с этими учетными данными. Успешное подключение подтверждает доступность сервиса.
        *   **Qdrant:**
            *   Найдите URL для Qdrant (вероятно, он будет доступен только внутри сети Coolify, но если вы пробросили порт наружу или используете Coolify Proxy, у вас может быть и внешний URL. Для проверки взаимодействия из Node.js приложения достаточно внутреннего).
            *   Если у вас есть доступ к окружению, откуда виден Qdrant (например, через SSH в контейнер Node.js или используя прокси), выполните: `curl http://test-qdrant:6333/` или `curl http://test-qdrant:6333/collections`. Должен вернуться ответ от Qdrant API (например, информация о сервере или пустой список коллекций).

    Если все эти шаги прошли успешно, вы подтвердили, что ваш стек (Node.js + PostgreSQL + Qdrant) может быть развернут и базово взаимодействовать в среде Coolify.

**Результат Фазы 1:**
- Настроенный репозиторий проекта.
- Рабочая локальная среда разработки.
- Базовый Dockerfile.
- Скрипт для получения исходных MD-файлов из Git.
- Проверенное подключение к **PostgreSQL** и Qdrant.
- Подтвержденная возможность развертывания стека на Coolify.

### **Фаза 2: Предобработка Markdown (Оценка: 5-8 дней)**

**Цель:** Реализовать **единый автоматизированный скрипт**, который находит все `.docx` и `.md` файлы для указанного модуля в локальной копии Git-репозитория (склонированного в Фазе 1), конвертирует `docx` в `md` с помощью `pandoc`, заменяет теги изображений (`img`) на Mermaid-диаграммы (через LLM), и разделяет итоговый Markdown-контент на логические части (чанки) по заголовкам.

1.  **Настройка Зависимостей и Окружения:**
    *   Убедиться, что `pandoc` установлен и доступен в `PATH` среды выполнения скрипта (локально и в Docker). Добавить инструкции по установке в `Dockerfile` и `README.md`.
    *   Установить npm-зависимости: `remark`, `remark-parse`, `unist-util-visit`, `axios`/`node-fetch` (для LLM API), `glob` (для поиска файлов), `yargs` (для аргументов командной строки), `child_process` (для запуска `pandoc`).

2.  **Реализация Автоматической Конвертации DOCX -> MD:**
    *   Создать функцию, использующую `child_process` для вызова `pandoc` с параметрами (`-f docx -t gfm --extract-media=./media --wrap=none -o <output.md>`).
    *   Функция должна обрабатывать ошибки `pandoc`.
    *   **Проверка Предположения 1 (Pandoc):** Автоматически протестировать конвертацию на реальных `.docx` файлах, проверяя корректность `.md` и папок `media`.

3.  **Реализация Замены Изображений на Mermaid:**
    *   Установить зависимости для парсинга MD (`remark`, `unist-util-visit`).
    *   Реализовать функцию парсинга MD для поиска тегов изображений (`![]()`, `<img>`).
    *   Реализовать интеграцию с OpenRouter API:
        *   Установить HTTP-клиент (`axios`/`node-fetch`).
        *   Настроить вызов API с промптом (из конфигурации), контекстом изображения (alt, path, окружение).
        *   Обработать ответы и ошибки API.
    *   Реализовать логику замены тега изображения в AST Markdown на блок Mermaid ```mermaid ... ```.
    *   **Проверка Предположения 2 (LLM для Mermaid):** Протестировать генерацию Mermaid на разных примерах. 
    *   **Проверка Предположения 7 (API Limits - OpenRouter):** Мониторить лимиты во время тестов.

4.  **Реализация Разделения по Заголовкам и Ограничению Размера:**
    *   Используя `remark`, реализовать логику разделения MD-документа на чанки:
        *   **Первичный сплит:** На основе уровня заголовка (уровень настраивается в `.env`, например `SPLITTING_HEADER_LEVEL=2`).
        *   **Вторичный сплит (при необходимости):** Если чанк, полученный после разделения по заголовку, превышает максимальное количество символов (лимит настраивается в `.env`, например `MAX_CHUNK_CHAR_LENGTH=2000`), то этот чанк должен быть дополнительно разделен на более мелкие под-чанки, не превышающие лимит. Разделение должно происходить по границам предложений или абзацев, чтобы сохранить семантическую целостность.
    *   Для каждого итогового чанка (или под-чанка) сохранять: текст, `source_file_name`, `module_id`, иерархию заголовков (до уровня первичного сплита), порядковый номер (`chunk_index`), и, возможно, индекс под-чанка (`sub_chunk_index`).
    *   **Проверка Предположения 5 (Стратегия Сплиттинга):** Протестировать на реальных документах, оценить качество чанков, выбрать оптимальный уровень заголовка *и* оптимальный лимит символов. Проверить, что вторичное разделение не нарушает логическую связность текста.

5.  **Создание Единого Скрипта Предобработки (`scripts/preprocess.js`):**
    *   Использовать `yargs` для получения аргумента `--module=<id>`.
    *   Определить путь к директории модуля в локальном репозитории.
    *   Использовать `glob` для поиска всех `.docx` файлов в директории модуля.
    *   Для каждого `.docx`: вызвать функцию конвертации (п.2). Сохранять исходный `.docx`.
    *   Использовать `glob` для поиска всех `.md` файлов (включая сконвертированные).
    *   Асинхронно обработать каждый `.md`:
        *   Прочитать файл.
        *   Вызвать функцию замены изображений на Mermaid (п.3).
        *   Вызвать функцию разделения на чанки (п.4).
        *   Собрать все чанки модуля в один массив.
    *   Добавить логирование всех этапов с использованием `pino`/`winston`.
    *   Записать итоговый массив чанков в JSON-файл (например, `output/preprocessed_chunks_${moduleId}.json`).
    *   Настроить запуск скрипта через `npm run preprocess -- --module=<id>`.

6.  **Обновление Документации (`README.md`):**
    *   Убрать секцию про ручную конвертацию DOCX.
    *   Добавить требование установки `pandoc`.
    *   Описать работу единого скрипта `preprocess.js`.

7.  **Интеграция с Git-репозиторием Источников (`source_md`):**
    *   **Цель:** Автоматически получать актуальную версию файлов документации (`.md`, `.docx`) из отдельного Git-репозитория перед запуском скрипта предобработки.
    *   **Компоненты:**
        *   *Удаленный Git-репозиторий:* Отдельный репозиторий с исходными файлами.
        *   *Скрипт `src/utils/git_fetcher.js`:* Отвечает за клонирование (`git clone`) или обновление (`git pull`) локальной копии.
        *   *Конфигурация `.env`:* Переменные `GIT_REPO_URL` (URL репозитория), `SOURCE_MD_ROOT_DIR` (локальная папка, например, `source_md/`), данные для аутентификации (SSH-ключ или HTTPS-токен).
    *   **Процесс:**
        1.  **Настройка `.env`:** Задать `GIT_REPO_URL`, `SOURCE_MD_ROOT_DIR`.
        2.  **Настройка Аутентификации:**
            *   *SSH (Рекомендуется):* Сгенерировать ключ, добавить публичный ключ в Git-провайдер, обеспечить доступ к приватному ключу для скрипта (через ssh-agent, `GIT_SSH_COMMAND` или `GIT_SSH_KEY_PATH` в `.env` + модификация `git_fetcher.js`). **Безопасность ключей критична!**
            *   *HTTPS с Токеном:* Сгенерировать токен доступа (PAT) у Git-провайдера, настроить Git Credential Manager (предпочтительно) или использовать переменную `GIT_ACCESS_TOKEN` в `.env` с доработкой `git_fetcher.js`. **Безопасность токенов критична!**
        3.  **Запуск Получения Данных:**
            *   *Рекомендация:* Интегрировать вызов функции из `git_fetcher.js` (например, `fetchAndUpdateRepo()`) в начало скрипта `scripts/preprocess.mjs`, чтобы гарантировать актуальность данных перед каждой обработкой.
            *   *Альтернатива:* Ручной запуск `node src/utils/git_fetcher.js`.
        4.  **Логика `git_fetcher.js`:** Проверяет наличие `SOURCE_MD_ROOT_DIR`. Если нет - клонирует, если есть - выполняет `pull`. Обрабатывает ошибки. (Функция `findModules` пока заглушка).
    *   **Результат:** Актуальная копия репозитория с документацией в `SOURCE_MD_ROOT_DIR`, готовая для обработки скриптом `preprocess.mjs`.

**Результат Фазы 2:**
- Инструкции по установке `pandoc`.
- Рабочий модуль автоматической конвертации DOCX -> MD.
- Рабочий модуль замены изображений на Mermaid (через LLM).
- Рабочий модуль разделения MD по заголовкам.
- Единый скрипт предобработки (`scripts/preprocess.js`), запускаемый через npm.
- Проверенные предположения 1, 2, 5, 7.
- Обновленный `README.md`.

### **Фаза 3: Webhook и Автоматизация Пайплайна (Оценка: 4-6 дней)**

**Цель:** Реализовать автоматический запуск полного конвейера обработки при коммите в репозиторий документации и публикацию результатов обработки обратно в Git-репозиторий приложения.

1.  **Реализация HTTP Сервера и Webhook Эндпоинта:**
    *   Добавить зависимость `express` (или аналог) в `package.json`.
    *   Создать базовый HTTP-сервер (`src/server.js` или аналогичный).
    *   Реализовать эндпоинт (например, `POST /webhook/docs-push`), который будет слушать входящие запросы.
    *   Настроить сервер на прослушивание порта, указанного в `WEBHOOK_LISTENER_PORT`.

1.1. **Настройка GitHub Webhook (в репозитории Документации):**
    *   Перейти в `Settings` -> `Webhooks` репозитория документации на GitHub.
    *   Нажать `Add webhook`.
    *   **Payload URL:** Указать URL эндпоинта, развернутого на Coolify (например, `https://<ваш_домен_coolify_приложения>/webhook/docs-push`).
    *   **Content type:** Выбрать `application/json`.
    *   **Secret:** Указать **тот же** секрет, который будет использоваться для валидации в приложении (значение переменной `WEBHOOK_SECRET` из Coolify).
    *   **Which events would you like to trigger this webhook?:** Выбрать `Just the push event`.
    *   Убедиться, что опция `Active` включена.
    *   Сохранить webhook.

2.  **Обработка Webhook Payload:**
    *   Реализовать парсинг тела POST-запроса от Git-провайдера (GitHub/GitLab).
    *   Извлечь информацию об измененных/добавленных файлах (`.docx`/`.md`) в коммите.
    *   Определить уникальные `module_id`, соответствующие этим файлам.
    *   (Рекомендуется) Реализовать валидацию подписи webhook'а с использованием секрета `WEBHOOK_SECRET`.

3.  **Асинхронный Запуск Конвейера:**
    *   Сразу после парсинга и валидации, для каждого найденного `module_id`:
        *   **Немедленно** отправить ответ `200 OK` Git-провайдеру.
        *   **Асинхронно** инициировать запуск полного конвейера обработки. Рассмотреть варианты:
            *   `child_process.spawn`: Запустить последовательно команды `npm run preprocess -- --module=<id>` и `npm run pipeline -- --module=<id>`.
            *   Система очередей (например, `BullMQ`): Поставить задачу в очередь на выполнение полного пайплайна для `module_id`.
    *   Обеспечить логирование старта и возможных ошибок при запуске.

4.  **Реализация Публикации Результатов в Git (в репозиторий Документации):**
    *   Создать новый скрипт (например, `scripts/publish_results.js`) или добавить логику в конец скрипта `pipeline`.
    *   Скрипт должен принимать `module_id`.
    *   **Логика Git:**
        *   Использовать `simple-git` или `child_process`.
        *   Настроить Git (имя пользователя, email).
        *   Клонировать/обновить **репозиторий документации** (`GIT_REPO_URL`) во временную папку, используя токен/ключ `GIT_DOCS_WRITE_SSH_KEY_PATH`/`TOKEN`.
        *   Очистить целевую папку для результатов этого модуля (`<module_id>/processed_chunks/`) в клоне.
        *   Скопировать все `.md` файлы чанков из локальной папки `source_md/<module_id>/processed_chunks/` (из постоянного хранилища) в целевую папку в клоне.
        *   Выполнить `git add <module_id>/processed_chunks`, `git commit -m "Update processed chunks for module <module_id>"`, `git push origin <ветка>`.
    *   Обработать возможные ошибки Git.

5.  **Обновление Конфигурации и Документации:**
    *   Добавить/переименовать переменные окружения (`GIT_DOCS_WRITE_SSH_KEY_PATH`/`TOKEN`, `GIT_DOCS_WRITE_TARGET_BRANCH`) в `.env.example` с комментариями. Удалить переменные для пуша в репо приложения.
    *   Обновить `Dockerfile`, если требуется открыть порт или установить доп. зависимости (например, для очереди задач).
    *   Обновить `README.md`: добавить секцию по настройке webhook'а в репозитории документации, описать новые переменные, объяснить автоматический процесс и **структуру папки `processed_chunks` с результатами в репозитории документации**.

**Результат Фазы 3:**

-   Рабочий HTTP-сервер с эндпоинтом для приема webhook'ов.
-   Реализован парсинг payload и валидация секрета webhook'а.
-   Настроен асинхронный запуск полного пайплайна (`preprocess` + `pipeline`) для модуля.
-   Реализован скрипт/логика для коммита и пуша обработанных чанков (`.md`) обратно в репозиторий **документации**.
-   Обновлены `.env.example`, `Dockerfile` (при необходимости) и `README.md` (включая переменные `GIT_DOCS_WRITE_...`).

### **Фаза 4: Основной Конвейер - LLM и PostgreSQL (Оценка: 5-7 дней)**

**Цель:** Реализовать обработку чанков с помощью LLM для извлечения информации и сохранение результатов в **PostgreSQL**. *Эта фаза остается такой же, как в v1.3, но теперь ее результаты используются как входные для Фазы 5 (Векторизация)*.

1.  **Создание Скрипта Основного Конвейера (`src/pipeline.js` или `scripts/pipeline.js`):**
    *   Скрипт будет запускаться командой `npm run pipeline -- --module=<id>`.
    *   Использовать `yargs` для получения `module_id`.
    *   Настроить клиенты **`pg` (или выбранный ORM)** и `axios`/`node-fetch` (для OpenRouter API), используя конфигурацию из `.env`.
    *   Настроить логирование (`pino`/`winston`).

2.  **Чтение Обработанных Чанков:**
    *   Скрипт определяет путь к директории чанков: `source_md/<module_id>/processed_chunks/`.
    *   Используя `fs.readdir`, `path.join`, `fs.readFile`, читает содержимое каждого `.md` файла в директории. Текст файла - это текст чанка.
    *   Из имени файла извлекается порядковый номер (`chunk_index`).

3.  **Интеграция с LLM (OpenRouter) для Извлечения Информации:**
    *   Для каждого текста чанка:
        *   Реализовать функцию `processChunkWithLLM(chunkText)`.
        *   Функция формирует промпт (из `.env` или `prompts.js`), включающий текст чанка и задачу (например, генерация вопросов).
        *   Выполняет API-запрос к OpenRouter.
        *   Обрабатывает ответ, извлекая сгенерированную информацию (например, массив вопросов).
        *   Реализует базовую обработку ошибок API (логирование, возможно, повторные попытки).
    *   *Опционально (для оптимизации):* Рассмотреть асинхронную параллельную обработку чанков (`Promise.all`, `p-limit`).

4.  **Реализация Сохранения в PostgreSQL:**
    *   Убедиться, что запись для `document` (соответствующая `module_id`) существует или создать ее в таблице `documents`, получить `document_id`.
    *   Создать функции-хелперы (используя клиент `pg` или ORM):
        *   `saveChunkToDB(chunkText, chunkIndex, documentId, moduleId)`: Сохраняет текст чанка, его индекс, `document_id`, `module_id` в таблицу `chunks`. Получает `chunk_id`.
        *   `saveQuestionsToDB(questions, chunkId, documentId)`: Сохраняет массив сгенерированных вопросов, связывая каждый с `chunk_id` и `document_id` в таблице `questions`.
    *   Использовать соответствующие методы клиента PostgreSQL (например, `pool.query` или методы ORM).

5.  **Логирование и Управление Потоком:**
    *   Добавить логирование на всех этапах (чтение, LLM, **PostgreSQL**) с указанием `module_id` и `chunk_index`.
    *   Обеспечить последовательное выполнение для каждого чанка (чтение -> LLM -> сохранение).
    *   По завершении выводить итоговую статистику.

**Результат Фазы 4:**

-   Рабочий скрипт `pipeline.js`, обрабатывающий чанки для указанного модуля.
-   Реализована интеграция с OpenRouter API для извлечения информации из чанков.
-   Реализована схема БД в **PostgreSQL** (`documents`, `chunks`, `questions`).
-   Рабочие функции для сохранения данных в **PostgreSQL**.
-   Часть основного конвейера (`pipeline`), читающая `.md` файлы чанков, обрабатывающая их через LLM и сохраняющая результаты в **PostgreSQL**.
-   Проверенное предположение 3 (если оно относится к LLM).

### **Фаза 5: Векторизация Вопросов и Qdrant (Оценка: 3-5 дней)**

**Цель:** Реализовать векторизацию **сгенерированных вопросов** из PostgreSQL с помощью `vsegpt.ru` и их загрузку в Qdrant для обеспечения семантического поиска.

**Предварительные шаги (Настройка Qdrant и vsegpt.ru):**

1.  **Настройка Qdrant:**
    *   **Развертывание:** Убедитесь, что у вас есть работающий экземпляр Qdrant (например, развернутый на Coolify в Фазе 1 или 6, или доступный по URL).
    *   **API Ключ (если используется):** Если ваш Qdrant требует аутентификации, сгенерируйте или получите API ключ.
    *   **Переменные окружения:** В `.env` файле проекта установите переменные:
        *   `QDRANT_URL`: Полный URL вашего экземпляра Qdrant (например, `http://your-qdrant-instance:6333`).
        *   `QDRANT_API_KEY` (опционально): Ваш API ключ, если требуется.
        *   `QDRANT_COLLECTION_NAME`: Имя коллекции, которую будет использовать приложение (например, `scpl_qa_vectors`).
    *   **Создание Коллекции (Важно!):** Перед первым запуском пайплайна (или как часть инициализации приложения) необходимо **создать коллекцию** в Qdrant с правильной конфигурацией. Это можно сделать либо через клиент Qdrant (`@qdrant/js-client`) в коде приложения при старте или в отдельном скрипте инициализации, либо вручную через UI/API Qdrant. Примерные параметры:
        *   Имя: Значение из `QDRANT_COLLECTION_NAME`.
        *   Размерность векторов: Нужно уточнить у `vsegpt.ru`, какая размерность у их эмбеддингов (например, 768, 1024 и т.д.). Указать это значение при создании коллекции.
        *   Метрика расстояния: Обычно `Cosine` или `Dot Product` подходят для текстовых эмбеддингов.

2.  **Настройка vsegpt.ru:**
    *   **Регистрация и API Ключ:** Зарегистрируйтесь на `vsegpt.ru` (или аналогичном сервисе, предоставляющем API для текстовых эмбеддингов) и получите API ключ.
    *   **Переменная окружения:** В `.env` файле проекта установите переменную:
        *   `VSEGPT_API_KEY`: Ваш API ключ для сервиса векторизации.
    *   **Уточнение модели/эндпоинта:** Убедитесь, что вы знаете правильный эндпоинт API и, возможно, имя модели, которую нужно использовать для получения эмбеддингов, а также ожидаемую размерность векторов.

---

**Основные шаги реализации:**

1.  **Интеграция с vsegpt.ru API:**
    *   Создать модуль (`src/services/vectorizer.js` или аналогичный) для инкапсуляции логики вызова API `vsegpt.ru`.
    *   Реализовать функцию, принимающую массив текстов (вопросов) и возвращающую массив соответствующих векторов.
    *   Использовать `VSEGPT_API_KEY` из `.env` для аутентификации.
    *   Обработать ошибки API.

2.  **Интеграция с Qdrant:**
    *   Использовать `@qdrant/js-client`, настроенный с `QDRANT_URL`, `QDRANT_API_KEY` из `.env`.
    *   Реализовать функции для:
        *   Проверки существования коллекции (`QDRANT_COLLECTION_NAME`) и, возможно, её создания с нужными параметрами (размерность, метрика), если она не существует (см. Предварительные шаги).
        *   Загрузки/обновления точек (векторов) в Qdrant (`upsert`).

3.  **Доработка Скрипта Основного Конвейера (`pipeline`, Часть 2):**
    *   Модифицировать скрипт `npm run pipeline -- --module=<id>`:
        *   **После** шага сохранения данных в PostgreSQL (Фаза 4), выполнить **SQL-запрос к таблице `questions`** для извлечения всех **текстов вопросов**, их `question_id`, а также связанных `chunk_id` и `document_id` для указанного `module_id`.
        *   Передать извлеченные тексты вопросов в модуль векторизации (`vectorizer.js`) для получения векторов от `vsegpt.ru`.
        *   Для каждого вопроса и его вектора подготовить payload, включающий как минимум:
            *   `question_text`: Сам текст вопроса.
            *   `question_id`: ID вопроса из PostgreSQL.
            *   `chunk_id`: ID чанка, к которому относится вопрос.
            *   `document_id`: ID документа (модуля).
            *   `module_id`: ID модуля (для фильтрации).
        *   Загрузить векторы вопросов и их payload в коллекцию `QDRANT_COLLECTION_NAME` в Qdrant, используя `question_id` или UUID в качестве ID точки в Qdrant.
        *   **(Изменено)** **Удален** вызов скрипта/функции публикации результатов в репозиторий документации.
    *   Обеспечить последовательное выполнение шагов конвейера (LLM/PostgreSQL -> Vsegpt/Qdrant).
    *   Добавить логирование этапа векторизации **вопросов** и загрузки в Qdrant.

**Результат Фазы 5:**

*   Настроены доступы и переменные окружения для Qdrant и vsegpt.ru.
*   Создана и настроена коллекция в Qdrant для хранения векторов вопросов.
*   Рабочая интеграция с API vsegpt.ru для векторизации **текстов вопросов**.
*   Рабочая интеграция с Qdrant для загрузки векторов **вопросов** с `module_id` и другой релевантной метаинформацией (включая `question_id`, `chunk_id`).
*   Обновленный основной конвейер (`pipeline`), выполняющий шаги от чтения файлов чанков до загрузки векторов **вопросов** в Qdrant. Пайплайн **не** инициирует публикацию в репозиторий документации.
*   Проверенные предположения 4 (API vsegpt) и 7 (лимиты API).

### **Фаза 6: Развертывание, Документация и Тестирование (Оценка: 5-7 дней)**

**Цель:** Подготовить приложение к развертыванию, обновить документацию с учетом автоматизации, провести комплексное тестирование и подготовить пакет для передачи клиенту.

1.  **Доработка Dockerfile и Конфигурации:**
    *   (Без изменений от v1.3, но проверить актуальность с учетом Фазы 3)
2.  **Настройка Развертывания на Coolify:**
    *   Создать/обновить конфигурацию сервисов в Coolify:
        *   Приложение Node.js (убедиться, что **команда запуска** запускает HTTP-сервер из Фазы 3, например `node src/server.js`).
        *   (Изменено) База данных **PostgreSQL**.
        *   (Без изменений) Векторная база данных Qdrant.
    *   Настроить **все** переменные окружения и секреты, включая добавленные/измененные в Фазах 3 и 5 (например, `DATABASE_URL`, `QDRANT_URL`, `QDRANT_API_KEY`, `QDRANT_COLLECTION_NAME`, `VSEGPT_API_KEY`). **Удалены** переменные `GIT_DOCS_WRITE_...`.
    *   (Без изменений) Настроить сетевое взаимодействие.
    *   Протестировать **автоматический запуск** конвейера через **отправку тестового webhook'а** или **реальный коммит** в репозиторий документации.

3.  **Тестирование:**
    *   (Без изменений) Модульное тестирование.
    *   (Без изменений) Интеграционное тестирование.
    *   **End-to-End Тестирование:** Запустить **полный автоматический цикл** (коммит в репо документации -> webhook -> обработка -> проверка данных в **PostgreSQL**/Qdrant) для нескольких тестовых модулей. **Проверка коммита с результатами в репозитории документации удалена.**

4.  **Обновление Документации (`README.md`):**
    *   (Без изменений) Описать проект, архитектуру, настройку среды.
    *   (Без изменений) Инструкция по `pandoc` (если применимо).
    *   (Без изменений) Структура входных данных в Git.
    *   (Обновлено) Объяснить **все** переменные окружения в `.env.example` (включая `DATABASE_URL`, `QDRANT_URL`, `QDRANT_API_KEY`, `QDRANT_COLLECTION_NAME`, `VSEGPT_API_KEY`). **Удалены** переменные `GIT_DOCS_WRITE_...`.
    *   (Обновлено) Пошаговые инструкции по развертыванию **всего** стека на Coolify (**включая PostgreSQL**).
    *   (Обновлено) **Детально описать настройку webhook'а** в репозитории документации (URL, секрет, события).
    *   (Обновлено) **Описать автоматический рабочий процесс**. **Описание структуры папки `processed_chunks` с результатами в репозитории документации удалено**.
    *   (Опционально) Описать команды для ручного запуска `preprocess` и `pipeline` для отладки.
    *   (Обновлено) Структура БД **PostgreSQL** и Qdrant (указать, что вектора в Qdrant соответствуют вопросам).
    *   (Без изменений) Troubleshooting.

**Результат Фазы 6:**

*   Готовый к развертыванию Docker-образ приложения с HTTP-сервером.
*   Настроенные конфигурации для развертывания на Coolify.
*   Проведены тесты, включая **сквозное тестирование автоматического пайплайна**.
*   Исчерпывающая документация `README.md`, включающая инструкции по настройке webhook'а. **Удалены инструкции по правам на запись в репо документации и описание папки с результатами**.
*   Актуальный файл `.env.example` (с переменными **`DATABASE_URL`, `QDRANT_*`, `VSEGPT_API_KEY`**. **Удалены** `GIT_DOCS_WRITE_...`.

### **Фаза 7: Передача Проекта Клиенту (Оценка: 1-2 дня)**

**Цель:** Передать все артефакты проекта клиенту и обеспечить понимание процесса использования и развертывания **автоматизированной системы**.

1.  **Подготовка Пакета Передачи:**
    *   (Без изменений) Убедиться, что репозиторий Приложения содержит всё необходимое.
2.  **Передача Доступа:**
    *   (Без изменений) Доступ к Git-репозиторию Приложения.
3.  **Демонстрация и Обучение (Опционально):**
    *   Провести демонстрацию **автоматической работы системы** (коммит -> проверка данных в Qdrant/PostgreSQL).
    *   Объяснить процесс настройки (включая **webhook**, **подключение к PostgreSQL**, **настройку Qdrant/vsegpt.ru**), развертывания на Coolify, следуя `README.md`.
    *   Ответить на вопросы клиента.
4.  **Фиксация Завершения:**
    *   (Без изменений) Получить подтверждение.

**Результат Фазы 7:**

*   Клиент получил доступ к репозиторию Приложения.
*   Клиент ознакомлен с документацией и процессом работы **автоматизированной системы**.

**Общая Оценка Трудозатрат:** ~26-38 рабочих дней (без учета времени на ожидание доступов, согласования, непредвиденные сложности). Рекомендуется добавить буфер (~15-25%).

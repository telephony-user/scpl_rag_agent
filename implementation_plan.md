**Детализированный План Реализации и Передачи Проекта (на основе PRD v1.3)**

### **Фаза 1: Подготовка и Базовая Настройка (Оценка: 3-5 дней)**

**Цель:** Создать основу проекта, настроить окружение и обеспечить базовый доступ к данным.
1. **Создание Репозитория Проекта:**
    - Инициализировать Git-репозиторий для кода Node.js.
    - Настроить базовую структуру папок (src, scripts, config, tests, docs).
    - Создать `.gitignore` (включить `.env`, `node_modules`, `dist`, и т.д.).
2. **Настройка Среды Разработки:**
    - Следовать "Руководству по Настройке Среды Разработки" из `prd_assumptions_setup_guide`.
    - Установить Node.js, npm, Docker, Pandoc.
    - Создать базовый `package.json`.
    - Установить основные зависимости: `dotenv`, фреймворк для логирования (`pino`/`winston`), базовые утилиты.
	
3. **Настройка Docker (Базовая):**
    - Создать начальный `Dockerfile` для Node.js приложения.
    - (Опционально) Создать `docker-compose.yml` для локального запуска PostgreSQL и Qdrant (для разработки/тестирования).
	
4. **Настройка Доступа к Git (Источник MD):**
    - Реализовать скрипт/модуль на Node.js (используя `simple-git` или `child_process`) для:
        - Клонирования/обновления репозитория с MD-файлами по URL из `.env`.
        - Обработки аутентификации (SSH-ключ/токен из `.env`).
        - Определения `module_id` по структуре папок.
    - Настроить переменные окружения (`GIT_REPO_URL`, `GIT_SSH_KEY_PATH`/`GIT_ACCESS_TOKEN`).
        
5. **Настройка Подключения к Базам Данных:**
    - Установить клиенты: `@supabase/supabase-js`, `@qdrant/js-client`.
    - Реализовать модули конфигурации для подключения к Supabase/PostgreSQL и Qdrant, используя данные из `.env`.
    - Написать простые тесты подключения к БД (локально или на Coolify).
    - Настроить переменные окружения (`SUPABASE_URL`, `SUPABASE_ANON_KEY`, `QDRANT_URL`, `QDRANT_API_KEY` и т.д.).
        
6. **Проверка Предположения 6 (Coolify):**
    
    - Развернуть "hello-world" Node.js, PostgreSQL, Qdrant на Coolify.

    Хорошо, давайте детально разберем, как выполнить пункт 1.6 для проверки развертывания на Coolify, используя созданный `hello-world` пример.

    **Предварительные шаги:**

    1.  **Git Репозиторий:** Убедитесь, что папка `hello-world` со всеми файлами (`index.js`, `package.json`, `Dockerfile`, `docker-compose.yml`) добавлена, закоммичена и отправлена (pushed) в Git-репозиторий (например, на GitHub, GitLab, Bitbucket), к которому у вашего Coolify есть доступ.
    2.  **Доступ Coolify: как настроить подключение к Git-репозиторию?**
        - Войдите в веб‑интерфейс Coolify → раздел «Settings» → «Integrations» → «Git Provider».
        - Для SSH‑доступа:
            1. Сгенерируйте SSH‑ключ: ssh-keygen -t ed25519 -C "coolify".
            2. Добавьте публичный ключ (id_ed25519.pub) в раздел SSH‑keys вашего репозитория на GitHub/GitLab.
            3. В настройках Coolify загрузите приватный ключ (id_ed25519).
        - Для доступа через GitHub App:
            1. Нажмите «Connect with GitHub» и авторизуйте Coolify как GitHub App.
            2. Выберите нужные репозитории и подтвердите доступ.
        - Убедитесь, что статус подключения отображается как «Connected», а ваш репозиторий доступен для деплоя.

    **Шаги в интерфейсе Coolify:**

    1.  **Вход и Создание Проекта:**
        *   Войдите в свой Coolify.
        *   Перейдите в раздел "Projects".
        *   Нажмите "Create New Project".
        *   Дайте проекту имя, например, `SCPL Test Deployment`.

    2.  **Добавление Источника (Source):**
        *   Внутри нового проекта перейдите на вкладку "Sources".
        *   Нажмите "Add Source".
        *   Выберите ваш Git-провайдер (GitHub, GitLab и т.д.).
        *   Выберите репозиторий, содержащий ваш проект (включая папку `hello-world`).

    3.  **Развертывание PostgreSQL:**
        *   Перейдите на вкладку "Resources" вашего проекта.
        *   Нажмите "Add Resource".
        *   Выберите тип ресурса: "PostgreSQL".
        *   Задайте имя сервиса, например, `test-postgres`.
        *   Выберите желаемую версию PostgreSQL (например, 15).
        *   Coolify обычно автоматически генерирует пользователя, пароль и имя базы данных. Вы можете найти их на вкладке "Environment Variables" созданного ресурса PostgreSQL *после* первого деплоя, или задать свои переменные `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB` перед деплоем.
        *   Нажмите "Deploy". Дождитесь статуса `Running`.

    4.  **Развертывание Qdrant:**
        *   Снова нажмите "Add Resource".
        *   Выберите тип ресурса: "Qdrant" (если доступно) или "Docker Image".
            *   **Если выбрали "Qdrant":**
                *   Задайте имя, например, `test-qdrant`.
                *   Убедитесь, что порт `6333` указан.
                *   Если используете API-ключ, добавьте переменную окружения `QDRANT_API_KEY` с вашим ключом.
            *   **Если выбрали "Docker Image":**
                *   Задайте имя, например, `test-qdrant`.
                *   В поле "Image" укажите `qdrant/qdrant:v1.7.4`.
                *   В настройках сети (Networking) укажите порт `6333`.
                *   Если используете API-ключ, добавьте переменную окружения `QDRANT_API_KEY` с вашим ключом.
        *   Нажмите "Deploy". Дождитесь статуса `Running`.

    5.  **Развертывание Node.js Приложения (`hello-world`):**
        *   Снова нажмите "Add Resource".
        *   Выберите тип ресурса: "Application".
        *   **General:**
            *   Задайте имя, например, `test-hello-world-app`.
            *   Выберите Git Source (ваш репозиторий) и нужную ветку.
        *   **Build:**
            *   Выберите "Dockerfile" как Build Pack.
            *   **Dockerfile Location:** `/hello-world/Dockerfile` (Путь от корня репозитория).
            *   **Base Directory:** `/hello-world/` (Указывает, что команды типа `COPY` в Dockerfile должны работать относительно этой папки).
        *   **Network:**
            *   **Ports:** Укажите `3000` (порт, который слушает ваше Node.js приложение). Coolify автоматически назначит внешний порт.
        *   **(Опционально, для демонстрации связей)**: На вкладке "Environment Variables" можно добавить переменные для подключения к другим сервисам, используя внутренние DNS-имена Coolify (они обычно совпадают с именами сервисов):
            *   `POSTGRES_URL=postgresql://<user>:<password>@test-postgres:5432/<database>` (замените `<user>`, `<password>`, `<database>` на значения из шага 3).
            *   `QDRANT_URL=http://test-qdrant:6333`
            *   (Хотя само приложение `hello-world` их не использует, это показывает, как вы будете настраивать основное приложение).
        *   Нажмите "Deploy". Дождитесь статуса `Running`.

    6.  **Проверка и Валидация:**
        *   Убедитесь, что все три ресурса (`test-postgres`, `test-qdrant`, `test-hello-world-app`) имеют статус `Running`.
        *   Проверьте логи каждого ресурса на вкладке "Logs" на наличие ошибок запуска или работы.

    7.  **Тестирование Сетевого Взаимодействия:**
        *   **Node.js App:**
            *   На странице ресурса `test-hello-world-app` сгенерированный FQDN (Public URL) : 
            *   Откройте в браузере или используйте `curl`: `curl http://<ваш-fqdn>/health`. Вы должны увидеть ответ `OK`.
        *   **PostgreSQL:**
            *   На странице ресурса `test-postgres` найдите данные для подключения (хост, порт, пользователь, пароль, база данных). Они могут быть доступны как переменные окружения или на отдельной вкладке.
            *   Используйте любой SQL-клиент (psql, DBeaver, pgAdmin) для подключения к базе данных с этими учетными данными. Успешное подключение подтверждает доступность сервиса.
        *   **Qdrant:**
            *   Найдите URL для Qdrant (вероятно, он будет доступен только внутри сети Coolify, но если вы пробросили порт наружу или используете Coolify Proxy, у вас может быть и внешний URL. Для проверки взаимодействия из Node.js приложения достаточно внутреннего).
            *   Если у вас есть доступ к окружению, откуда виден Qdrant (например, через SSH в контейнер Node.js или используя прокси), выполните: `curl http://test-qdrant:6333/` или `curl http://test-qdrant:6333/collections`. Должен вернуться ответ от Qdrant API (например, информация о сервере или пустой список коллекций).

    Если все эти шаги прошли успешно, вы подтвердили, что ваш стек (Node.js + PostgreSQL + Qdrant) может быть развернут и базово взаимодействовать в среде Coolify.

**Результат Фазы 1:**
- Настроенный репозиторий проекта.
- Рабочая локальная среда разработки.
- Базовый Dockerfile.
- Скрипт для получения исходных MD-файлов из Git.
- Проверенное подключение к Supabase и Qdrant.
- Подтвержденная возможность развертывания стека на Coolify.

### **Фаза 2: Предобработка Markdown (Оценка: 5-8 дней)**

**Цель:** Реализовать **единый автоматизированный скрипт**, который находит все `.docx` и `.md` файлы для указанного модуля в локальной копии Git-репозитория (склонированного в Фазе 1), конвертирует `docx` в `md` с помощью `pandoc`, заменяет теги изображений (`img`) на Mermaid-диаграммы (через LLM), и разделяет итоговый Markdown-контент на логические части (чанки) по заголовкам.

1.  **Настройка Зависимостей и Окружения:**
    *   Убедиться, что `pandoc` установлен и доступен в `PATH` среды выполнения скрипта (локально и в Docker). Добавить инструкции по установке в `Dockerfile` и `README.md`.
    *   Установить npm-зависимости: `remark`, `remark-parse`, `unist-util-visit`, `axios`/`node-fetch` (для LLM API), `glob` (для поиска файлов), `yargs` (для аргументов командной строки), `child_process` (для запуска `pandoc`).

2.  **Реализация Автоматической Конвертации DOCX -> MD:**
    *   Создать функцию, использующую `child_process` для вызова `pandoc` с параметрами (`-f docx -t gfm --extract-media=./media --wrap=none -o <output.md>`).
    *   Функция должна обрабатывать ошибки `pandoc`.
    *   **Проверка Предположения 1 (Pandoc):** Автоматически протестировать конвертацию на реальных `.docx` файлах, проверяя корректность `.md` и папок `media`.

3.  **Реализация Замены Изображений на Mermaid:**
    *   Установить зависимости для парсинга MD (`remark`, `unist-util-visit`).
    *   Реализовать функцию парсинга MD для поиска тегов изображений (`![]()`, `<img>`).
    *   Реализовать интеграцию с OpenRouter API:
        *   Установить HTTP-клиент (`axios`/`node-fetch`).
        *   Настроить вызов API с промптом (из конфигурации), контекстом изображения (alt, path, окружение).
        *   Обработать ответы и ошибки API.
    *   Реализовать логику замены тега изображения в AST Markdown на блок Mermaid ```mermaid ... ```.
    *   **Проверка Предположения 2 (LLM для Mermaid):** Протестировать генерацию Mermaid на разных примерах. 
    *   **Проверка Предположения 7 (API Limits - OpenRouter):** Мониторить лимиты во время тестов.

4.  **Реализация Разделения по Заголовкам и Ограничению Размера:**
    *   Используя `remark`, реализовать логику разделения MD-документа на чанки:
        *   **Первичный сплит:** На основе уровня заголовка (уровень настраивается в `.env`, например `SPLITTING_HEADER_LEVEL=2`).
        *   **Вторичный сплит (при необходимости):** Если чанк, полученный после разделения по заголовку, превышает максимальное количество символов (лимит настраивается в `.env`, например `MAX_CHUNK_CHAR_LENGTH=2000`), то этот чанк должен быть дополнительно разделен на более мелкие под-чанки, не превышающие лимит. Разделение должно происходить по границам предложений или абзацев, чтобы сохранить семантическую целостность.
    *   Для каждого итогового чанка (или под-чанка) сохранять: текст, `source_file_name`, `module_id`, иерархию заголовков (до уровня первичного сплита), порядковый номер (`chunk_index`), и, возможно, индекс под-чанка (`sub_chunk_index`).
    *   **Проверка Предположения 5 (Стратегия Сплиттинга):** Протестировать на реальных документах, оценить качество чанков, выбрать оптимальный уровень заголовка *и* оптимальный лимит символов. Проверить, что вторичное разделение не нарушает логическую связность текста.

5.  **Создание Единого Скрипта Предобработки (`scripts/preprocess.js`):**
    *   Использовать `yargs` для получения аргумента `--module=<id>`.
    *   Определить путь к директории модуля в локальном репозитории.
    *   Использовать `glob` для поиска всех `.docx` файлов в директории модуля.
    *   Для каждого `.docx`: вызвать функцию конвертации (п.2). Сохранять исходный `.docx`.
    *   Использовать `glob` для поиска всех `.md` файлов (включая сконвертированные).
    *   Асинхронно обработать каждый `.md`:
        *   Прочитать файл.
        *   Вызвать функцию замены изображений на Mermaid (п.3).
        *   Вызвать функцию разделения на чанки (п.4).
        *   Собрать все чанки модуля в один массив.
    *   Добавить логирование всех этапов с использованием `pino`/`winston`.
    *   Записать итоговый массив чанков в JSON-файл (например, `output/preprocessed_chunks_${moduleId}.json`).
    *   Настроить запуск скрипта через `npm run preprocess -- --module=<id>`.

6.  **Обновление Документации (`README.md`):**
    *   Убрать секцию про ручную конвертацию DOCX.
    *   Добавить требование установки `pandoc`.
    *   Описать работу единого скрипта `preprocess.js`.

7.  **Интеграция с Git-репозиторием Источников (`source_md`):**
    *   **Цель:** Автоматически получать актуальную версию файлов документации (`.md`, `.docx`) из отдельного Git-репозитория перед запуском скрипта предобработки.
    *   **Компоненты:**
        *   *Удаленный Git-репозиторий:* Отдельный репозиторий с исходными файлами.
        *   *Скрипт `src/utils/git_fetcher.js`:* Отвечает за клонирование (`git clone`) или обновление (`git pull`) локальной копии.
        *   *Конфигурация `.env`:* Переменные `GIT_REPO_URL` (URL репозитория), `SOURCE_MD_ROOT_DIR` (локальная папка, например, `source_md/`), данные для аутентификации (SSH-ключ или HTTPS-токен).
    *   **Процесс:**
        1.  **Настройка `.env`:** Задать `GIT_REPO_URL`, `SOURCE_MD_ROOT_DIR`.
        2.  **Настройка Аутентификации:**
            *   *SSH (Рекомендуется):* Сгенерировать ключ, добавить публичный ключ в Git-провайдер, обеспечить доступ к приватному ключу для скрипта (через ssh-agent, `GIT_SSH_COMMAND` или `GIT_SSH_KEY_PATH` в `.env` + модификация `git_fetcher.js`). **Безопасность ключей критична!**
            *   *HTTPS с Токеном:* Сгенерировать токен доступа (PAT) у Git-провайдера, настроить Git Credential Manager (предпочтительно) или использовать переменную `GIT_ACCESS_TOKEN` в `.env` с доработкой `git_fetcher.js`. **Безопасность токенов критична!**
        3.  **Запуск Получения Данных:**
            *   *Рекомендация:* Интегрировать вызов функции из `git_fetcher.js` (например, `fetchAndUpdateRepo()`) в начало скрипта `scripts/preprocess.mjs`, чтобы гарантировать актуальность данных перед каждой обработкой.
            *   *Альтернатива:* Ручной запуск `node src/utils/git_fetcher.js`.
        4.  **Логика `git_fetcher.js`:** Проверяет наличие `SOURCE_MD_ROOT_DIR`. Если нет - клонирует, если есть - выполняет `pull`. Обрабатывает ошибки. (Функция `findModules` пока заглушка).
    *   **Результат:** Актуальная копия репозитория с документацией в `SOURCE_MD_ROOT_DIR`, готовая для обработки скриптом `preprocess.mjs`.

**Результат Фазы 2:**
- Инструкции по установке `pandoc`.
- Рабочий модуль автоматической конвертации DOCX -> MD.
- Рабочий модуль замены изображений на Mermaid (через LLM).
- Рабочий модуль разделения MD по заголовкам.
- Единый скрипт предобработки (`scripts/preprocess.js`), запускаемый через npm.
- Проверенные предположения 1, 2, 5, 7.
- Обновленный `README.md`.

### **Фаза 3: Webhook и Автоматизация Пайплайна (Оценка: 4-6 дней)**

**Цель:** Реализовать автоматический запуск полного конвейера обработки при коммите в репозиторий документации и публикацию результатов обработки обратно в Git-репозиторий приложения.

1.  **Реализация HTTP Сервера и Webhook Эндпоинта:**
    *   Добавить зависимость `express` (или аналог) в `package.json`.
    *   Создать базовый HTTP-сервер (`src/server.js` или аналогичный).
    *   Реализовать эндпоинт (например, `POST /webhook/docs-push`), который будет слушать входящие запросы.
    *   Настроить сервер на прослушивание порта, указанного в `WEBHOOK_LISTENER_PORT`.

1.1. **Настройка GitHub Webhook (в репозитории Документации):**
    *   Перейти в `Settings` -> `Webhooks` репозитория документации на GitHub.
    *   Нажать `Add webhook`.
    *   **Payload URL:** Указать URL эндпоинта, развернутого на Coolify (например, `https://<ваш_домен_coolify_приложения>/webhook/docs-push`).
    *   **Content type:** Выбрать `application/json`.
    *   **Secret:** Указать **тот же** секрет, который будет использоваться для валидации в приложении (значение переменной `WEBHOOK_SECRET` из Coolify).
    *   **Which events would you like to trigger this webhook?:** Выбрать `Just the push event`.
    *   Убедиться, что опция `Active` включена.
    *   Сохранить webhook.

2.  **Обработка Webhook Payload:**
    *   Реализовать парсинг тела POST-запроса от Git-провайдера (GitHub/GitLab).
    *   Извлечь информацию об измененных/добавленных файлах (`.docx`/`.md`) в коммите.
    *   Определить уникальные `module_id`, соответствующие этим файлам.
    *   (Рекомендуется) Реализовать валидацию подписи webhook'а с использованием секрета `WEBHOOK_SECRET`.

3.  **Асинхронный Запуск Конвейера:**
    *   Сразу после парсинга и валидации, для каждого найденного `module_id`:
        *   **Немедленно** отправить ответ `200 OK` Git-провайдеру.
        *   **Асинхронно** инициировать запуск полного конвейера обработки. Рассмотреть варианты:
            *   `child_process.spawn`: Запустить последовательно команды `npm run preprocess -- --module=<id>` и `npm run pipeline -- --module=<id>`.
            *   Система очередей (например, `BullMQ`): Поставить задачу в очередь на выполнение полного пайплайна для `module_id`.
    *   Обеспечить логирование старта и возможных ошибок при запуске.

4.  **Реализация Публикации Результатов в Git:**
    *   Создать новый скрипт (например, `scripts/publish_results.js`) или добавить логику в конец скрипта `pipeline`.
    *   Скрипт должен принимать `module_id`.
    *   **Логика Git:**
        *   Использовать `simple-git` или `child_process`.
        *   Настроить Git (имя пользователя, email), используя переменные окружения или глобальные настройки Git в контейнере.
        *   Клонировать/обновить **репозиторий приложения** (`GIT_APP_REPO_URL`) во временную папку, используя токен/ключ `GIT_RESULTS_PUSH_TOKEN`/`KEY_PATH`.
        *   Очистить целевую папку для результатов этого модуля (например, `output/processed_results/<module_id>/`) в клонированном репозитории.
        *   Скопировать все `.md` файлы чанков из папки `source_md/<module_id>/processed_chunks/` (из постоянного хранилища) в целевую папку.
        *   Выполнить `git add .`, `git commit -m "Update results for module <module_id>"`, `git push`.
    *   Обработать возможные ошибки Git (конфликты, ошибки аутентификации, ошибки сети).

5.  **Обновление Конфигурации и Документации:**
    *   Добавить новые переменные окружения (`WEBHOOK_SECRET`, `GIT_APP_REPO_URL`, `GIT_RESULTS_PUSH_TOKEN`/`KEY_PATH`, `WEBHOOK_LISTENER_PORT`) в `.env.example` с комментариями.
    *   Обновить `Dockerfile`, если требуется открыть порт или установить доп. зависимости (например, для очереди задач).
    *   Обновить `README.md`: добавить секцию по настройке webhook'а в репозитории документации, описать новые переменные, объяснить автоматический процесс и структуру папки с результатами в репозитории приложения.

**Результат Фазы 3:**

-   Рабочий HTTP-сервер с эндпоинтом для приема webhook'ов.
-   Реализован парсинг payload и валидация секрета webhook'а.
-   Настроен асинхронный запуск полного пайплайна (`preprocess` + `pipeline`) для модуля.
-   Реализован скрипт/логика для коммита и пуша обработанных чанков (`.md`) в репозиторий приложения.
-   Обновлены `.env.example`, `Dockerfile` (при необходимости) и `README.md`.

### **Фаза 4: Основной Конвейер - LLM и Supabase (Оценка: 5-7 дней)**

**Цель:** Реализовать обработку чанков с помощью LLM для извлечения информации и сохранение результатов в Supabase. *Эта фаза остается такой же, как в v1.3, но теперь ее результаты используются как входные для Фазы 5 (Векторизация)*.

1.  **Интеграция с LLM для Извлечения Информации:**
    *   (Без изменений)
2.  **Реализация Сохранения в Supabase:**
    *   (Без изменений)
3.  **Создание/Доработка Скрипта Основного Конвейера (`pipeline`, Часть 1):**
    *   Скрипт (`npm run pipeline --module=<id>`) должен:
        *   (Изменено) **Читать чанки** не из промежуточного JSON, а **из сохраненных `.md` файлов** в `source_md/<module_id>/processed_chunks/`.
        *   Вызывать LLM для каждого чанка.
        *   Сохранять результаты (документ, чанки, вопросы) в Supabase.
    *   Добавить логирование.

**Результат Фазы 4:**

-   Рабочая интеграция с LLM для извлечения структурированной информации из файлов чанков.
-   Реализована схема БД в Supabase.
-   Рабочие функции для сохранения данных в Supabase.
-   Часть основного конвейера (`pipeline`), читающая файлы чанков, обрабатывающая их через LLM и сохраняющая в Supabase.
-   Проверенное предположение 3.

### **Фаза 5: Векторизация и Qdrant (Оценка: 4-6 дней)**

**Цель:** Реализовать векторизацию данных из Supabase и их загрузку в Qdrant. *Эта фаза остается такой же, как в v1.3, но запускается как часть автоматического пайплайна*.

4.  **Интеграция с vsegpt.ru API:**
    *   (Без изменений)
5.  **Интеграция с Qdrant:**
    *   (Без изменений)
6.  **Доработка Скрипта Основного Конвейера (`pipeline`, Часть 2):**
    *   Добавить в скрипт `npm run pipeline --module=<id>`:
        *   Чтение необходимых данных (чанков/вопросов) из Supabase для указанного `module_id`.
        *   Вызов API vsegpt.ru для векторизации.
        *   Загрузку векторов и payload в Qdrant.
        *   (Изменено) **По завершении**, инициировать вызов скрипта/функции **публикации результатов в Git** (из Фазы 3, п.4).
    *   Обеспечить последовательное выполнение шагов конвейера (LLM/Supabase -> Vsegpt/Qdrant -> Publish Results).
    *   Добавить логирование этапа векторизации.

**Результат Фазы 5:**

-   Рабочая интеграция с API vsegpt.ru для векторизации.
-   Рабочая интеграция с Qdrant для загрузки векторов с `module_id`.
-   Завершенный основной конвейер (`pipeline`), выполняющий шаги от чтения файлов чанков до загрузки векторов и инициирующий публикацию результатов.
-   Проверенные предположения 4 и 7.

### **Фаза 6: Развертывание, Документация и Тестирование (Оценка: 5-7 дней)**

**Цель:** Подготовить приложение к развертыванию, обновить документацию с учетом автоматизации, провести комплексное тестирование и подготовить пакет для передачи клиенту.

7.  **Доработка Dockerfile и Конфигурации:**
    *   (Без изменений от v1.3, но проверить актуальность с учетом Фазы 3)
8.  **Настройка Развертывания на Coolify:**
    *   Создать/обновить конфигурацию сервисов в Coolify:
        *   Приложение Node.js (убедиться, что **команда запуска** запускает HTTP-сервер из Фазы 3, например `node src/server.js`).
        *   (Без изменений) База данных PostgreSQL/Supabase.
        *   (Без изменений) Векторная база данных Qdrant.
    *   Настроить **все** переменные окружения и секреты, включая добавленные в Фазе 3.
    *   (Без изменений) Настроить сетевое взаимодействие.
    *   Протестировать **автоматический запуск** конвейера через **отправку тестового webhook'а** или **реальный коммит** в репозиторий документации.

9.  **Тестирование:**
    *   (Без изменений) Модульное тестирование.
    *   (Без изменений) Интеграционное тестирование.
    *   **End-to-End Тестирование:** Запустить **полный автоматический цикл** (коммит в репо документации -> webhook -> обработка -> проверка данных в Supabase/Qdrant -> проверка коммита с результатами в репо приложения) для нескольких тестовых модулей.

10. **Обновление Документации (`README.md`):**
    *   (Без изменений) Описать проект, архитектуру, настройку среды.
    *   (Без изменений) Инструкция по `pandoc` (если применимо).
    *   (Без изменений) Структура входных данных в Git.
    *   (Обновлено) Объяснить **все** переменные окружения в `.env.example` (включая новые).
    *   (Обновлено) Пошаговые инструкции по развертыванию **всего** стека на Coolify.
    *   (Обновлено) **Детально описать настройку webhook'а** в репозитории документации (URL, секрет, события).
    *   (Обновлено) **Описать автоматический рабочий процесс** и **структуру папки с результатами** в репозитории приложения.
    *   (Опционально) Описать команды для ручного запуска `preprocess` и `pipeline` для отладки.
    *   (Без изменений) Структура БД и Qdrant.
    *   (Без изменений) Troubleshooting.

**Результат Фазы 6:**

-   Готовый к развертыванию Docker-образ приложения с HTTP-сервером.
-   Настроенные конфигурации для развертывания на Coolify.
-   Проведены тесты, включая **сквозное тестирование автоматического пайплайна**.
-   Исчерпывающая документация `README.md`, включающая инструкции по настройке webhook'а.
-   Актуальный файл `.env.example`.

### **Фаза 7: Передача Проекта Клиенту (Оценка: 1-2 дня)**

**Цель:** Передать все артефакты проекта клиенту и обеспечить понимание процесса использования и развертывания **автоматизированной системы**.

11. **Подготовка Пакета Передачи:**
    *   (Без изменений) Убедиться, что репозиторий Приложения содержит всё необходимое.
12. **Передача Доступа:**
    *   (Без изменений) Доступ к Git-репозиторию Приложения.
13. **Демонстрация и Обучение (Опционально):**
    *   Провести демонстрацию **автоматической работы системы** (коммит -> результат).
    *   Объяснить процесс настройки (включая **webhook**), развертывания на Coolify, следуя `README.md`.
    *   Ответить на вопросы клиента.
14. **Фиксация Завершения:**
    *   (Без изменений) Получить подтверждение.

**Результат Фазы 7:**

-   Клиент получил доступ к репозиторию Приложения.
-   Клиент ознакомлен с документацией и процессом работы **автоматизированной системы**.

**Общая Оценка Трудозатрат:** ~27-40 рабочих дней (без учета времени на ожидание доступов, согласования, непредвиденные сложности). Рекомендуется добавить буфер (~15-25%).
